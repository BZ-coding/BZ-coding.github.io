<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>loss on 张胜东的博客</title><link>https://www.zhangshengdong.com/tags/loss/</link><description>Recent content in loss on 张胜东的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>&lt;a href="https://beian.miit.gov.cn/" target="_blank">苏ICP备15009593号-1&lt;/a></copyright><lastBuildDate>Tue, 11 Feb 2025 23:54:58 +0800</lastBuildDate><atom:link href="https://www.zhangshengdong.com/tags/loss/index.xml" rel="self" type="application/rss+xml"/><item><title>GRPO Loss初期为0的原因与改进方法</title><link>https://www.zhangshengdong.com/post/grpo_loss/</link><pubDate>Tue, 11 Feb 2025 23:54:58 +0800</pubDate><guid>https://www.zhangshengdong.com/post/grpo_loss/</guid><description>引言 在家里自己用OpenR1准备从qwen-base训出个R1模型来，结果跑了demo数据，发现前100多步的loss几乎都是0： 在搜索相关</description></item></channel></rss>